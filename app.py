import streamlit as st
from pathlib import Path
import pdfplumber
from docx import Document
import pypandoc
import requests
from bs4 import BeautifulSoup


st.title("CV Butler")

#! gemma3 model is being used here, the best that my hardware could support.
#! attempted using larger models but ran into issues.
#! the solution was inspired from:
#! • https://www.youtube.com/watch?v=bp2eev21Qfo - this was to understand how models are set up locally and called via API.
#! • https://www.youtube.com/watch?v=EECUXqFrwbc&list=WL&index=2 - this was to understand how to structure the solution.


def call_ollama(prompt, model="gemma3:4b"):
    payload = {"model": model, "prompt": prompt, "stream": False}
    resp = requests.post("http://localhost:11434/api/generate", json=payload)
    return resp.json().get("response", "")


job_file = st.file_uploader("Upload Job Description", type=["html"])
job_text = ""
if job_file:

    file_bytes = job_file.read()
    text_html = file_bytes.decode("utf-8")

    job_path = Path("job_description.html")
    with open(job_path, "wb") as f:
        f.write(file_bytes)

    text_html_clean = text_html.encode(
        'ascii', errors='ignore').decode('utf-8')
    clean_html_path = Path("job_description_clean.html")
    with open(clean_html_path, "w", encoding="utf-8") as f:
        f.write(text_html_clean)

    #! file had to be converted to pdf from html because ollama model was not reacting well to html input.
    #! this also explains why the ascii encoding step was needed.
    #! no reason to have picked pdf output.
    #! due to time constraints, i did not explore the issue further and bootstrapped with this solution.
    #! i considered allowing pdf upload directly from user, but i decided to keep the ux streamlined.

    output_pdf = Path("job_description.pdf")
    try:
        pypandoc.convert_file(str(clean_html_path), 'pdf',
                              outputfile=str(output_pdf))

    except Exception as e:
        st.error(f"The job description is not in the desired format: {e}")

    soup = BeautifulSoup(text_html_clean, "html.parser")
    job_text = soup.get_text(separator="\n")

    #! ai generated the prompts to follow the best principles of propmt engineering.
    #! the prompt is not set up for FrieslandCampina specifically to test the job descriptions from enough real companies with mostly real resumes.

    if "job_context" not in st.session_state and job_text.strip():
        job_prompt = (
            f"Read and fully comprehend the following job description. Extract and summarize its key responsibilities, required skills, and desired experience, "
            f"ensuring the information is clear and concise for HR evaluation. Present the summary in a structured, labeled format with three sections: "
            f"'Responsibilities': List main tasks and goals. 'Required Skills': List technical, analytical, and interpersonal skills. "
            f"'Desired Experience': Detail years of experience, industry background, certifications, or education. Organize each section with bullet points for readability. "
            f"Do not copy text directly; paraphrase for clarity. This structured summary will be used to compare candidate resumes for role fit.\n\n"
            f"Job Description:\n{job_text}"
        )

        with st.spinner("Analyzing job description..."):
            job_summary = call_ollama(job_prompt)
            st.session_state["job_context"] = job_summary

    st.text("Job Description processed.")

resume_files = st.file_uploader(
    "Upload Resumes", type=["pdf", "docx"], accept_multiple_files=True
)

#! even though the model is running locally, i decided to anonymize the resume data before analysis.
#! i did it because of the uncertainty around what data the model was trained on.
#! i wanted to make sure that the analysis did not get influenced by personal data.

if "anonymized_resumes" not in st.session_state:
    st.session_state["anonymized_resumes"] = {}

if resume_files:
    candidate_counter = 1

    for resume in resume_files:
        if resume.name not in st.session_state["anonymized_resumes"]:

            if resume.name.endswith(".pdf"):
                text = ""
                with pdfplumber.open(resume) as pdf:
                    for page in pdf.pages:
                        text += page.extract_text() + "\n"
            elif resume.name.endswith(".docx"):
                doc = Document(resume)
                text = "\n".join([p.text for p in doc.paragraphs])
            else:
                text = ""

            #! prompt again generated by ai to ensure gdpr compliance.

            candidate_id = f"Candidate{candidate_counter:03d}"
            prompt = (
                f"Act as a senior HR recruiter and perform GDPR-compliant anonymization. "
                f"For the following resume, remove all personal identifiers such as full name, address, phone number, email, date of birth, gender, photo, links to social media, "
                f"and any other contact details. Assign the candidate reference number: {candidate_id}. "
                f"Retain job titles, employers, dates, locations (in non-identifiable form, e.g., city only), work experience, education, certifications, and skills. "
                f"Ensure the output contains only anonymized data or masked placeholders for redacted fields, ready for blind recruitment evaluation. "
                f"Resume:\n{text}"
            )
            anonymized_text = call_ollama(prompt)
            st.session_state["anonymized_resumes"][resume.name] = anonymized_text

            candidate_counter += 1

    st.text("All Resumes processed.")

st.subheader("Analysis")

#! the solution allows for multiple types of analysis along with a custom prompt option that the user can input.
#! the prompts would be made more specialized when setting this up for the company.

prompt_options = {
    "Alignment with Job Requirements": "Act as a senior HR recruiter. For each candidate resume, evaluate the alignment with the job description focusing on: Matching responsibilities, Relevant tools, technologies, and domain expertise. Appropriate seniority level. Meeting required qualifications such as degrees, certifications, languages. Provide a concise bullet summary per candidate and rank all candidates from best to worst alignment.",
    "Demonstrated Impact and Outcomes": "Act as a senior HR recruiter. For each candidate resume, assess the evidence of measurable results such as cost savings, revenue growth, efficiency improvements, and successful project delivery. Consider career progression, increased responsibilities, and promotions. Provide a brief summary for each candidate and rank them based on demonstrated impact.",
    "Core Skills and Competencies": "Act as a senior HR recruiter. For each candidate resume, evaluate role-specific hard skills and relevant soft skills like communication, collaboration, stakeholder management, problem-solving, and ownership. Summarize the skill fit per candidate and rank candidates according to skills match.",
    "Overall Fit": "Act as a senior HR recruiter evaluating candidate resumes against a given job description analysis. For each candidate, assess overall fit by considering: Alignment with job responsibilities, tools/technologies, domain expertise, seniority level, and qualifications (degrees, certifications, languages, work authorization). Demonstrated impact and outcomes such as measurable achievements and career progression. Core technical and transferable soft skills including communication, problem-solving, and ownership. Practical fit including values, work style, availability, and stability. For each candidate, provide 2-3 sentences explaining their overall suitability, with strengths and weaknesses. Then produce a final ranked list of all candidates from most to least suitable for the role, with a one-sentence rationale for each candidate’s ranking."}

for keyword, full_prompt_text in prompt_options.items():
    if st.button(f"{keyword}"):
        if "job_context" not in st.session_state or not st.session_state["anonymized_resumes"]:
            st.warning(
                "Please upload and process both job description and resumes first.")
        else:
            with st.spinner(f"Running analysis..."):

                combined_resumes_text = "\n\n".join(
                    f"{name}:\n{text}" for name, text in st.session_state["anonymized_resumes"].items()
                )
                full_prompt = (
                    f"Job Description Context:\n{st.session_state['job_context']}\n\n"
                    f"Resumes:\n{combined_resumes_text}\n\n"
                    f"Instruction:\n{full_prompt_text}"
                )
                final_result = call_ollama(full_prompt)
                st.text_area(f"{keyword} Analysis Result",
                             value=final_result, height=300)

#! custom prompt section.
#! giving the correct context to the model with the job description and resumes.

custom_prompt = st.text_area("Enter custom prompt here:", height=100)
if st.button("Send"):
    if custom_prompt.strip() == "":
        st.warning("Please enter a prompt")
    else:
        if "job_context" not in st.session_state or not st.session_state["anonymized_resumes"]:
            st.warning(
                "Please upload and process both job description and resumes first.")
        else:
            combined_resumes_text = "\n\n".join(
                f"{name}:\n{text}" for name, text in st.session_state["anonymized_resumes"].items()
            )
            full_prompt = (
                f"Job Description Context:\n{st.session_state['job_context']}\n\n"
                f"Resumes:\n{combined_resumes_text}\n\n"
                f"User Instruction:\n{custom_prompt}"
            )
            response = call_ollama(full_prompt)
            st.text_area("Response", value=response, height=300)
